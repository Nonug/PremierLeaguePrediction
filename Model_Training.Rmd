---
title: "Model Training"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(pacman)
p_load(
    "caret", "skimr", "RANN", "randomForest",
    "gbm", "xgboost", "caretEnsemble", "C50",
    BiocManager, doMC, DataExplorer, nnet, broom, glmnet, MLmetrics,
    dplyr, CatEncoders, yardstick, kernlab, pROC
)
```

## Import dataset
```{r}
train_df_timestamped <- read.csv("./data/training_data.csv")

train_df <- subset(train_df_timestamped,
    select = -c(Season, Date, Date_interval)
)

test_df <- read.csv("./data/testing_data.csv")
test_df <- subset(test_df, select = -c(Season, Date, Date_interval))
```

```{r}
# convert cat variables to factor
chr_cols <- c("FTR", "HomeTeam", "AwayTeam", "Referee")

# This step prevents errors when fitting test data to models
# if the levels of factors aren't the same.
for (col in chr_cols) {
    # Create a levels attribute with the unique values
    # from attribute1 from both test and train.
    level <- unique(c(train_df[, col], test_df[, col]))
    # Create a factor on train and test attribute1 with all
    # the levels found above.
    train_df[, col] <- factor(train_df[, col], levels = level)
    test_df[, col] <- factor(test_df[, col], levels = level)
}

# level <- unique(c(train_df$FTR, test_df$FTR))

# Store X and Y for later use.
y <- train_df$FTR
x <- subset(train_df, select = -c(FTR))
x_num <- subset(x, select = -c(HomeTeam, AwayTeam, Referee))
```

Plot distribution of A/D/H in training data
```{r}
ydist_plot <- ggplot(train_df, aes(FTR, fill = FTR)) +
    geom_bar() +
    geom_text(stat = "count", aes(
        label = round(
            ..count.. / sum(..count..), 3
        ),
        vjust = -1
    )) +
    ggtitle("Distribution of A/D/H in training data")

ydist_plot
ggsave(ydist_plot,
    filename = "./img/train_y_dist.png",
    height = 6, width = 6
)
```

Create DataExplorer report 
```{r}
# create_report(train_df, y = "FTR", output_file = "./reports/train_report.html")
# plot_bar(train_df)
```
### One-Hot Encoding
```{r}
# Converting a categorical variable to
# as many binary variables as here are categories.
dummies_model <- dummyVars(FTR ~ ., data = train_df)

# Create the dummy variables using predict.
# The Y variable (Purchase) will not be present in trainData_mat.
trainData_mat <- predict(dummies_model, newdata = train_df)

# Convert to dataframe
train_encoded <- data.frame(trainData_mat)

# See the structure of the new dataset
str(train_encoded)
colnames(train_encoded)
```

```{r}
# Converting a categorical variable to
# as many binary variables as here are categories.
dummies_model_test <- dummyVars(FTR ~ ., data = test_df)

# Create the dummy variables using predict.
# The Y variable (Purchase) will not be present in trainData_mat.
testData_mat <- predict(dummies_model_test, newdata = test_df)

# Convert to dataframe
test_encoded <- data.frame(testData_mat)

# See the structure of the new dataset
str(test_encoded)
colnames(test_encoded)
```



Feature plots (check ./img)
```{r}
# Defining a function to save lattice plots
lattice_save <- function(plot, name) {
    setwd("./img/")
    png(file = paste(name, ".png", sep = ""))
    plot(plot)
    dev.off() # Saving the file
    setwd("../")
}
# Generate a feature boxplot.
feature_boxplot <- featurePlot(
    x = x_num,
    y = y,
    plot = "box",
    strip = strip.custom(par.strip.text = list(cex = .7)),
    scales = list(
        x = list(relation = "free"),
        y = list(relation = "free")
    )
)

feature_density <- featurePlot(
    x = x_num,
    y = y,
    plot = "density",
    strip = strip.custom(par.strip.text = list(cex = .7)),
    scales = list(
        x = list(relation = "free"),
        y = list(relation = "free")
    )
)

lattice_save(feature_boxplot, "training_feature_boxplot")
lattice_save(feature_density, "training_feature_density")
```

## Multinomial Logistic Regression model with Cross Validation
### Using glmnet and caret
Set up train control 
```{r}
trControl <- trainControl(
    method = "repeatedcv",
    number = 5, # 5-fold CV
    repeats = 5, # repeat 5-fold CV 5 times
    p = 0.75, # the training percentage, default = 75%
    search = "grid", # grid search, Default
    savePredictions = "final", # saves predictions for optimal tuning parameter
    classProbs = T, # should class probabilities be returned
    summaryFunction = multiClassSummary, # results summary function
    verboseIter = T,
    allowParallel = T,
)
trControl_cv <- trainControl(
    method = "cv",
    number = 5, # 5-fold CV
    p = 0.75, # the training percentage, default = 75%
    search = "grid", # grid search, Default
    savePredictions = "final", # saves predictions for optimal tuning parameter
    classProbs = T, # should class probabilities be returned
    summaryFunction = multiClassSummary, # results summary function
    verboseIter = T,
    allowParallel = T,
)
```
```{r}
set.seed(3612)

# Elastic net multinom
multinom_CV <- train(
    form = FTR ~ .,
    data = train_df,
    trControl = trControl_cv,
    method = "glmnet",
    family = "multinomial"
)

multinom_CV
fitted <- predict(multinom_CV)
multinom_CV_plot <- ggplot(multinom_CV) +
    ggtitle("Model Accuracies with caret + glmnet Multinom")
ggsave(multinom_CV_plot,
    filename = "./img/Model Accuracies with caret + glmnet Multinom.png",
    height = 6, width = 6
)

sink(file = "./outputs/confmat_multinom.txt")
confusionMatrix(reference = y, data = fitted, mode = "everything")
sink(file = NULL)

# Feature importance
multinom_imp <- varImp(multinom_CV, scale = T)
multinom_imp_plot <- ggplot(multinom_imp, top = 20, aes(fill = feature)) +
    ggtitle("Feature importance ranked (top 20) in multinomial logit model")

ggsave(multinom_imp_plot,
    filename = "./img/multinom_imp.png",
    height = 6, width = 8
)
```

### Using nnet

Below we use the multinom function from the nnet package to estimate a 
multinomial logistic regression model using neural nets 
(out-of-syllabus? Drop this maybe)

```{r}
# # Training the multinomial model
# # DummyVar not required.
# multinom_model <- multinom(FTR ~ ., data = train_df, seed = 3612)
# # Checking the model
# summary(multinom_model)

# # Convert coef to prob, get first 6 predictions.
# head(round(fitted(multinom_model), 2))
```

#### Predicting & Validating

```{r}
# # Predicting the values for train dataset
# FTRPredicted <- predict(multinom_model, newdata = train_df, "class")
# # Building classification table
# tab <- table(y, FTRPredicted)
# # Calculating accuracy - sum of diagonal elements divided by total obs
# round((sum(diag(tab)) / sum(tab)) * 100, 2)
```



## Support Vector Machine

### Stock SVM using radial kernal
Accuracy = 0.6083
```{r}
svmfit <- svm(FTR ~ ., data = train_df, , probability = TRUE)
summary(svmfit)
svm_pred <- predict(svmfit, train_df, probability = TRUE)
confusionMatrix(reference = train_df$FTR, data = svm_pred, mode = "everything")
```

metrics
```{r}
roc_auc(as.numeric(train_df$FTR), attr(svm_pred, "probabilities"))
```
### SVM radial kernal using caret
```{r}

svmradial <- train(
    x = train_encoded,
    y = y,
    data = train_df,
    trControl = trControl_cv,
    method = "svmRadial",
)

svmradial
svmradial_pred <- predict(svmradial)
svmradial_plot <- plot(svmradial,
    main = "Model Accuracies with SVM (radial kernel)"
)
lattice_save(svmradial_plot, "Model Accuracies with SVM (radial kernel)")

sink(file = "./outputs/confmat_svm.txt")
confusionMatrix(reference = y, data = svmradial_pred, mode = "everything")
sink(file = NULL)


# svmradial_pred_test <- predict(svmradial, newdata = test_encoded)
# sink(file = "./outputs/confmat_svm_fwdlook_test.txt")
# confusionMatrix(reference = test_df$FTR, data = svmradial_pred_test, mode = "everything")
# sink(file = NULL)
```
Feature importance
```{r}
# Feature importance
svm_imp <- varImp(svmradial, scale = FALSE)
svm_imp_plot <- ggplot(svm_imp, top = 20, aes(fill = feature)) +
    ggtitle("Feature importance ranked (top 20) in SVM radial model")

ggsave(svm_imp_plot,
    filename = "./img/svmradial_imp.png",
    height = 6, width = 6
)
```

#### Test data results
```{r}
# svm_pred_test <- predict(svmfit, test_df)

# confusionMatrix(reference = test_df$FTR, data = svm_pred_test, mode = "everything")
```

### xgboost tree

```{r}
# set.seed(3612)
# # Encode y to [0,1,2] for xgboost
# y_encoder <- LabelEncoder.fit(y)
# y_encoded <- transform(y_encoder, y) - 1



# dtrain <- xgb.DMatrix(data = as.matrix(train_encoded), label = y_encoded)

# # tuning parameter grid
# grid_default <- expand.grid(
#     nrounds = 100, # nrounds: Number of trees, default: 100
#     max_depth = 6, # max_depth: Maximum tree depth, default: 6
#     eta = 0.3, # eta: Learning rate, default: 0.3
#     gamma = 0, # gamma: Used for tuning of Regularization, default: 0
#     colsample_bytree = 1, # colsample_bytree: Column sampling, default: 1
#     min_child_weight = 1, # min_child_weight: Minimum leaf weight, default: 1
#     subsample = 1 # subsample: Row sampling, default: 1
# )

# xgb_params <- list(
#     booster = "gbtree",
#     "objective" = "multi:softprob",
#     "eval_metric" = "mlogloss",
#     "num_class" = 3
# )
# nround <- 50 # number of XGBoost rounds
# cv.nfold <- 5

# xgboost_mod <- xgb.cv(
#     params = xgb_params,
#     nrounds = nround,
#     nfold = cv.nfold,
#     prediction = TRUE,
#     data = dtrain,
#     print_every_n = 10,
#     verbose = 1,
#     tree_method = "gpu_hist",
#     gpu_id = 0
# )

# # multiClassSummary(xgboost_mod)

# OOF_prediction <- data.frame(xgboost_mod$pred) %>%
#     mutate(
#         max_prob = inverse.transform(
#             y_encoder,
#             max.col(., ties.method = "last")
#         ),
#         label = inverse.transform(y_encoder, y_encoded + 1)
#     )

# head(OOF_prediction)
```

```{r}
# # confusion matrix
# confusionMatrix(factor(OOF_prediction$max_prob),
#     factor(OOF_prediction$label),
#     mode = "everything"
# )
# # Accuracy - 50%

# # view variable importance plot
# mat <- xgb.importance(model = xgboost_mod)
# xgb.plot.importance(importance_matrix = mat[1:20])
```

```{r}
set.seed(3612)
registerDoMC(cores = 4)
xgbtree_mod <- train(
    x = as.matrix(train_encoded),
    y = y,
    trControl = trControl_cv,
    method = "xgbTree",
    tree_method = "gpu_hist",
    gpu_id = 0,
    verbose = T
    # tuneLength = 5,
)

xgbtree_mod
fitted_xgbtree <- predict(xgbtree_mod)
xgbtree_mod_plot <- plot(xgbtree_mod,
    main = "Model Accuracies with caret + xgbTree"
)
lattice_save(xgbtree_mod_plot, "Model Accuracies with xgbTree")

sink(file = "./outputs/confmat_xgbtree.txt")
confusionMatrix(reference = y, data = fitted_xgbtree, mode = "everything")
sink(file = NULL)

# Feature importance
xgbtree_imp <- varImp(xgbtree_mod, scale = FALSE)
xgbtree_imp_plot <- ggplot(xgbtree_imp, top = 20, aes(fill = feature)) +
    ggtitle("Feature importance ranked (top 20) in xgbTree model")

ggsave(xgbtree_imp_plot,
    filename = "./img/xgbTree_imp.png",
    height = 6, width = 6
)
```

### XgbLinear + caret

## 
```{r}
set.seed(3612)
# cl <- makePSOCKcluster(3)
# registerDoParallel(cl)
## All subsequent models are then run in parallel
## When you are done:
# stopCluster(cl)



xgboost_mod <- train(
    x = as.matrix(train_encoded),
    y = y,
    trControl = trControl_cv,
    method = "xgbLinear",
    tree_method = "gpu_hist",
    gpu_id = 0,
    verbose = T
    # tuneLength = 5,
)

xgboost_mod
fitted_xgb <- predict(xgboost_mod)
xgboost_plot <- plot(xgboost_mod,
    main = "Model Accuracies with caret + xgbLinear"
)
lattice_save(xgboost_plot, "Model Accuracies with xgbLinear")

sink(file = "./outputs/confmat_xgblinear.txt")
confusionMatrix(reference = y, data = fitted_xgb, mode = "everything")
sink(file = NULL)

# Feature importance
xgb_imp <- varImp(xgboost_mod, scale = FALSE)
xgb_imp_plot <- ggplot(xgb_imp, top = 20, aes(fill = feature)) +
    ggtitle("Feature importance ranked (top 20) in xgbLinear model")

ggsave(xgb_imp_plot,
    filename = "./img/xgbLinear_imp.png",
    height = 6, width = 6
)
```

## Ensemble Model
```{r}
algorithmList <- c("glm", "xgbtree", "svmRadial")

set.seed(100)
models <- caretList(FTR ~ .,
    data = train_df,
    trControl = trainControl,
    methodList = algorithmList
)
results <- resamples(models)
summary(results)
```
## Compare different models
```{r}
res <- resamples(list(
    MULTINOM = multinom_CV,
    SVM = svmradial,
    XgbLinear = xgboost_mod,
    xgbTree = xgbtree_mod
))
sink(file = "./outputs/models_traindata_results_resampled.txt")
summary(res)
sink(file = NULL)

scale <- list(x = list(relation = "free"), y = list(relation = "free"))

for (metric in res$metrics) {
    bw_res_plot <- bwplot(res, scales = scale, metric = metric)
    lattice_save(
        bw_res_plot,
        paste("Model Evaluation Metrics (", metric, ")", sep = "")
    )
}
```
# Generate Test results
```{r}

multinom_pred <- predict(multinom_CV, test_df)
SVM_pred <- predict(svmradial, test_encoded)
XgbLinear_pred <- predict(xgboost_mod, test_encoded)
xgbTree_pred <- predict(xgbtree_mod, test_encoded)

# model_pred_list <- list(
#     multinom_CV = multinom_pred,
#     svmradial = SVM_pred,
#     xgboost_mod = XgbLinear_pred,
#     xgbtree_mod = xgbTree_pred
# )

model_pred_list <- data.frame(
    row.names = c("multinom_CV", "svmradial", "xgboost_mod", "xgbtree_mod"),
    val = c("multinom_pred", "SVM_pred", "XgbLinear_pred", "xgbTree_pred")
)

test_res <- cbind(
    test_df$FTR,
    predict(xgbtree_mod, newdata = test_encoded, type = "prob"), xgbTree_pred
)
colnames(test_res) <- c("obs", "D", "A", "H", "pred")

sink(file = paste("./outputs/", "xgbTree_pred", "_test_res.txt", sep = ""))
multiClassSummary(test_res, lev = levels(train_df$FTR), model = xgbtree_mod)
sink(file = NULL)


# for (rowname in rownames(model_pred_list)) {
#     pred_ <- model_pred_list[rowname, ]

#     test_res <- cbind(
#         test_df$FTR,
#         predict(eval(parse(text = rowname)), newdata = test_df, type = "prob"), eval(parse(text = pred_))
#     )
#     colnames(test_res) <- c("obs", "D", "A", "H", "pred")

#     sink(file = paste("./outputs/", rowname, "_test_res.txt", sep = ""))
#     multiClassSummary(test_res, lev = levels(train_df$FTR), model = eval(parse(text = rowname)))
#     sink(file = NULL)
# }
```



```{r}

multinom_prob <- predict(multinom_CV, newdata = test_df, type = "prob")

model.roc <- multiclass.roc(
    test_df$FTR,
    multinom_prob
)

metric(multinom_CV)

x11(width = 10, height = 3)
par(mfrow = c(1, 3))
for (contrast in names(model.roc$rocs)) {
    print(contrast)
    plot(model.roc$rocs[[contrast]][[1]], col = "green", main = contrast)
}
```